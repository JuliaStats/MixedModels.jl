<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Model constructors · MixedModels</title><meta name="title" content="Model constructors · MixedModels"/><meta property="og:title" content="Model constructors · MixedModels"/><meta property="twitter:title" content="Model constructors · MixedModels"/><meta name="description" content="Documentation for MixedModels."/><meta property="og:description" content="Documentation for MixedModels."/><meta property="twitter:description" content="Documentation for MixedModels."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="MixedModels logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">MixedModels</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">MixedModels.jl Documentation</a></li><li class="is-active"><a class="tocitem" href>Model constructors</a><ul class="internal"><li><a class="tocitem" href="#Examples-of-linear-mixed-effects-model-fits"><span>Examples of linear mixed-effects model fits</span></a></li><li><a class="tocitem" href="#Fitting-generalized-linear-mixed-models"><span>Fitting generalized linear mixed models</span></a></li><li class="toplevel"><a class="tocitem" href="#Extractor-functions"><span>Extractor functions</span></a></li><li><a class="tocitem" href="#Model-fit-statistics"><span>Model-fit statistics</span></a></li><li><a class="tocitem" href="#Fixed-effects-parameter-estimates"><span>Fixed-effects parameter estimates</span></a></li><li><a class="tocitem" href="#Covariance-parameter-estimates"><span>Covariance parameter estimates</span></a></li><li><a class="tocitem" href="#Conditional-modes-of-the-random-effects"><span>Conditional modes of the random effects</span></a></li><li><a class="tocitem" href="#Case-wise-diagnostics-and-residual-degrees-of-freedom"><span>Case-wise diagnostics and residual degrees of freedom</span></a></li></ul></li><li><a class="tocitem" href="../optimization/">Details of the parameter estimation</a></li><li><a class="tocitem" href="../GaussHermite/">Normalized Gauss-Hermite Quadrature</a></li><li><a class="tocitem" href="../prediction/">Prediction and simulation in Mixed-Effects Models</a></li><li><a class="tocitem" href="../bootstrap/">Parametric bootstrap for mixed-effects models</a></li><li><a class="tocitem" href="../rankdeficiency/">Rank deficiency in mixed-effects models</a></li><li><a class="tocitem" href="../mime/">Alternative display and output formats</a></li><li><a class="tocitem" href="../derivatives/">Gradient and Hessian computation</a></li><li><a class="tocitem" href="../formula_syntax/">Formula syntax</a></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Model constructors</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Model constructors</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaStats/MixedModels.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaStats/MixedModels.jl/blob/main/docs/src/constructors.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Model-constructors"><a class="docs-heading-anchor" href="#Model-constructors">Model constructors</a><a id="Model-constructors-1"></a><a class="docs-heading-anchor-permalink" href="#Model-constructors" title="Permalink"></a></h1><p>The <code>LinearMixedModel</code> type represents a linear mixed-effects model. Typically, it is constructed from a <code>Formula</code> and an appropriate <code>Table</code> type, usually a <code>DataFrame</code>.</p><h2 id="Examples-of-linear-mixed-effects-model-fits"><a class="docs-heading-anchor" href="#Examples-of-linear-mixed-effects-model-fits">Examples of linear mixed-effects model fits</a><a id="Examples-of-linear-mixed-effects-model-fits-1"></a><a class="docs-heading-anchor-permalink" href="#Examples-of-linear-mixed-effects-model-fits" title="Permalink"></a></h2><p>For illustration, several data sets from the <em>lme4</em> package for <em>R</em> are made available in <code>.arrow</code> format in this package. Often, for convenience, we will convert these to <code>DataFrame</code>s. These data sets include the <code>dyestuff</code> and <code>dyestuff2</code> data sets.</p><pre><code class="language-julia hljs">using DataFrames, MixedModels, MixedModelsDatasets, StatsModels
dyestuff = MixedModelsDatasets.dataset(:dyestuff)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Arrow.Table with 30 rows, 2 columns, and schema:
 :batch  String
 :yield  Int16</code></pre><pre><code class="language-julia hljs">describe(DataFrame(dyestuff))</code></pre><div><div style = "float: left;"><span>2×7 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">variable</th><th style = "text-align: left;">mean</th><th style = "text-align: left;">min</th><th style = "text-align: left;">median</th><th style = "text-align: left;">max</th><th style = "text-align: left;">nmissing</th><th style = "text-align: left;">eltype</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Symbol" style = "text-align: left;">Symbol</th><th title = "Union{Nothing, Float64}" style = "text-align: left;">Union…</th><th title = "Any" style = "text-align: left;">Any</th><th title = "Union{Nothing, Float64}" style = "text-align: left;">Union…</th><th title = "Any" style = "text-align: left;">Any</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "DataType" style = "text-align: left;">DataType</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">batch</td><td style = "font-style: italic; text-align: left;"></td><td style = "text-align: left;">A</td><td style = "font-style: italic; text-align: left;"></td><td style = "text-align: left;">F</td><td style = "text-align: right;">0</td><td style = "text-align: left;">String</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">yield</td><td style = "text-align: left;">1527.5</td><td style = "text-align: left;">1440</td><td style = "text-align: left;">1530.0</td><td style = "text-align: left;">1635</td><td style = "text-align: right;">0</td><td style = "text-align: left;">Int16</td></tr></tbody></table></div><h3 id="The-@formula-language-in-Julia"><a class="docs-heading-anchor" href="#The-@formula-language-in-Julia">The <code>@formula</code> language in Julia</a><a id="The-@formula-language-in-Julia-1"></a><a class="docs-heading-anchor-permalink" href="#The-@formula-language-in-Julia" title="Permalink"></a></h3><p><code>MixedModels.jl</code> builds on the <em>Julia</em> formula language provided by <a href="https://juliastats.org/StatsModels.jl/stable/formula/">StatsModels.jl</a>, which is similar to the formula language in <em>R</em> and is also based on the notation from Wilkinson and Rogers (<a href="https://dx.doi.org/10.2307/2346786">1973</a>). There are two ways to construct a formula in Julia.  The first way is to enclose the formula expression in the <code>@formula</code> macro:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsModels.@formula" href="#StatsModels.@formula"><code>StatsModels.@formula</code></a> — <span class="docstring-category">Macro</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">@formula(ex)</code></pre><p>Capture and parse a formula expression as a <code>FormulaTerm</code> struct.</p><p>A formula is an abstract specification of a dependence between <em>left-hand</em> and <em>right-hand</em> side variables as in, e.g., a regression model.  Each side specifies at a high level how tabular data is to be converted to a numerical matrix suitable for modeling.  This specification looks something like Julia code, is represented as a Julia <code>Expr</code>, but uses special syntax.  The <code>@formula</code> macro takes an expression like <code>y ~ 1 + a*b</code>, transforms it according to the formula syntax rules into a lowered form (like <code>y ~ 1 + a + b + a&amp;b</code>), and constructs a <code>FormulaTerm</code> struct which captures the original expression, the lowered expression, and the left- and right-hand-side.</p><p>Operators that have special interpretations in this syntax are</p><ul><li><code>~</code> is the formula separator, where it is a binary operator (the first argument is the left-hand side, and the second is the right-hand side.</li><li><code>+</code> concatenates variables as columns when generating a model matrix.</li><li><code>&amp;</code> represents an <em>interaction</em> between two or more variables, which corresponds to a row-wise kronecker product of the individual terms (or element-wise product if all terms involved are continuous/scalar).</li><li><code>*</code> expands to all main effects and interactions: <code>a*b</code> is equivalent to <code>a+b+a&amp;b</code>, <code>a*b*c</code> to <code>a+b+c+a&amp;b+a&amp;c+b&amp;c+a&amp;b&amp;c</code>, etc.</li><li><code>1</code>, <code>0</code>, and <code>-1</code> indicate the presence (for <code>1</code>) or absence (for <code>0</code> and <code>-1</code>) of an intercept column.</li></ul><p>The rules that are applied are</p><ul><li>The associative rule (un-nests nested calls to <code>+</code>, <code>&amp;</code>, and <code>*</code>).</li><li>The distributive rule (interactions <code>&amp;</code> distribute over concatenation <code>+</code>).</li><li>The <code>*</code> rule expands <code>a*b</code> to <code>a+b+a&amp;b</code> (recursively).</li><li>Subtraction is converted to addition and negation, so <code>x-1</code> becomes <code>x + -1</code> (applies only to subtraction of literal 1).</li><li>Single-argument <code>&amp;</code> calls are stripped, so <code>&amp;(x)</code> becomes the main effect <code>x</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsModels.jl/blob/v0.7.6/src/formula.jl#L23-L59">source</a></section></article><p>The second way is to combine <code>Term</code>s with operators like <code>+</code>, <code>&amp;</code>, <code>~</code>, and others at &quot;run time&quot;.  This is especially useful if you wish to create a formula from a list a variable names.  For instance, the following are equivalent:</p><pre><code class="language-julia hljs">@formula(y ~ 1 + a + b + a &amp; b) == (term(:y) ~ term(1) + term(:a) + term(:b) + term(:a) &amp; term(:b))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p><code>MixedModels.jl</code> provides additional formula syntax for representing <em>random-effects terms</em>.  Most importantly, <code>|</code> separates random effects and their grouping factors (as in the formula extension used by the <em>R</em> package <a href="https://cran.r-project.org/web/packages/lme4/index.html"><code>lme4</code></a>).  Much like with the base formula language, <code>|</code> can be used within the <code>@formula</code> macro and to construct a formula programmatically:</p><pre><code class="language-julia hljs">@formula(y ~ 1 + a + b + (1 + a + b | g))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">FormulaTerm
Response:
  y(unknown)
Predictors:
  1
  a(unknown)
  b(unknown)
  (a,b,g)-&gt;(1 + a + b) | g</code></pre><pre><code class="language-julia hljs">terms = sum(term(t) for t in [1, :a, :b])
group = term(:g)
response = term(:y)
response ~ terms + (terms | group)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">FormulaTerm
Response:
  y(unknown)
Predictors:
  1
  a(unknown)
  b(unknown)
  (1 + a + b | g)</code></pre><h3 id="Models-with-simple,-scalar-random-effects"><a class="docs-heading-anchor" href="#Models-with-simple,-scalar-random-effects">Models with simple, scalar random effects</a><a id="Models-with-simple,-scalar-random-effects-1"></a><a class="docs-heading-anchor-permalink" href="#Models-with-simple,-scalar-random-effects" title="Permalink"></a></h3><p>A basic model with simple, scalar random effects for the levels of <code>batch</code> (the batch of an intermediate product, in this case) is declared and fit as</p><pre><code class="language-julia hljs">fm = @formula(yield ~ 1 + (1|batch))
fm1 = fit(MixedModel, fm, dyestuff)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 yield ~ 1 + (1 | batch)
   logLik   -2 logLik     AIC       AICc        BIC    
  -163.6635   327.3271   333.3271   334.2501   337.5307

Variance components:
            Column    Variance Std.Dev.
batch    (Intercept)  1388.3332 37.2603
Residual              2451.2500 49.5101
 Number of obs: 30; levels of grouping factors: 6

  Fixed-effects parameters:
────────────────────────────────────────────────
              Coef.  Std. Error      z  Pr(&gt;|z|)
────────────────────────────────────────────────
(Intercept)  1527.5     17.6946  86.33    &lt;1e-99
────────────────────────────────────────────────</code></pre><p>You can also use the convenience function <code>lmm</code> to fit the model as follows:</p><pre><code class="language-julia hljs">fm = @formula(yield ~ 1 + (1|batch))
fm2 = lmm(fm, dyestuff)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 yield ~ 1 + (1 | batch)
   logLik   -2 logLik     AIC       AICc        BIC    
  -163.6635   327.3271   333.3271   334.2501   337.5307

Variance components:
            Column    Variance Std.Dev.
batch    (Intercept)  1388.3332 37.2603
Residual              2451.2500 49.5101
 Number of obs: 30; levels of grouping factors: 6

  Fixed-effects parameters:
────────────────────────────────────────────────
              Coef.  Std. Error      z  Pr(&gt;|z|)
────────────────────────────────────────────────
(Intercept)  1527.5     17.6946  86.33    &lt;1e-99
────────────────────────────────────────────────</code></pre><p>Notice that both are equivalent.</p><p>(If you are new to Julia you may find that this first fit takes an unexpectedly long time, due to Just-In-Time (JIT) compilation of the code. The subsequent calls to such functions are much faster.)</p><pre><code class="language-julia hljs">using BenchmarkTools
dyestuff2 = MixedModelsDatasets.dataset(:dyestuff2)
@benchmark fit(MixedModel, $fm, $dyestuff2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">BenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.
 Range <span class="sgr90">(</span><span class="sgr36"><span class="sgr1">min</span></span> … <span class="sgr35">max</span><span class="sgr90">):  </span><span class="sgr36"><span class="sgr1">212.928 μs</span></span> … <span class="sgr35">  9.561 ms</span>  <span class="sgr90">┊</span> GC <span class="sgr90">(</span>min … max<span class="sgr90">): </span>0.00% … 94.01%
 Time  <span class="sgr90">(</span><span class="sgr34"><span class="sgr1">median</span></span><span class="sgr90">):     </span><span class="sgr34"><span class="sgr1">232.715 μs               </span></span><span class="sgr90">┊</span> GC <span class="sgr90">(</span>median<span class="sgr90">):    </span>0.00%
 Time  <span class="sgr90">(</span><span class="sgr32"><span class="sgr1">mean</span></span> ± <span class="sgr32">σ</span><span class="sgr90">):   </span><span class="sgr32"><span class="sgr1">252.053 μs</span></span> ± <span class="sgr32">303.674 μs</span>  <span class="sgr90">┊</span> GC <span class="sgr90">(</span>mean ± σ<span class="sgr90">):  </span>5.64% ±  4.58%

     ▄▇▆▄▂▂▃▅██<span class="sgr34">▆</span>▃▁▁▁       <span class="sgr32"> </span>                                     
  ▂▃▇██████████<span class="sgr34">█</span>██████▆▆▆▆▇<span class="sgr32">▆</span>▆▆▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂ ▄
  213 μs<span class="sgr90">           Histogram: frequency by time</span>          309 μs <span class="sgr1">&lt;</span>

 Memory estimate<span class="sgr90">: </span><span class="sgr33">131.07 KiB</span>, allocs estimate<span class="sgr90">: </span><span class="sgr33">1047</span>.</code></pre><p>By default, the model is fit by maximum likelihood. To use the <code>REML</code> criterion instead, add the optional named argument <code>REML=true</code> to the call to <code>fit</code></p><pre><code class="language-julia hljs">fm1reml = fit(MixedModel, fm, dyestuff, REML=true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by REML
 yield ~ 1 + (1 | batch)
 REML criterion at convergence: 319.6542768422576

Variance components:
            Column    Variance Std.Dev.
batch    (Intercept)  1764.0503 42.0006
Residual              2451.2499 49.5101
 Number of obs: 30; levels of grouping factors: 6

  Fixed-effects parameters:
────────────────────────────────────────────────
              Coef.  Std. Error      z  Pr(&gt;|z|)
────────────────────────────────────────────────
(Intercept)  1527.5     19.3834  78.80    &lt;1e-99
────────────────────────────────────────────────</code></pre><h3 id="Floating-point-type-in-the-model"><a class="docs-heading-anchor" href="#Floating-point-type-in-the-model">Floating-point type in the model</a><a id="Floating-point-type-in-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#Floating-point-type-in-the-model" title="Permalink"></a></h3><p>The type of <code>fm1</code></p><pre><code class="language-julia hljs">typeof(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">LinearMixedModel{Float64}</code></pre><p>includes the floating point type used internally for the various matrices, vectors, and scalars that represent the model. At present, this will always be <code>Float64</code> because the parameter estimates are optimized using the <a href="https://github.com/JuliaOpt/NLopt.jl"><code>NLopt</code> package</a> which calls compiled C code that only allows for optimization with respect to a <code>Float64</code> parameter vector.</p><p>So in theory other floating point types, such as <code>BigFloat</code> or <code>Float32</code>, can be used to define a model but in practice only <code>Float64</code> works at present.</p><blockquote><p>In theory, theory and practice are the same.  In practice, they aren&#39;t.  – Anon</p></blockquote><h3 id="Simple,-scalar-random-effects"><a class="docs-heading-anchor" href="#Simple,-scalar-random-effects">Simple, scalar random effects</a><a id="Simple,-scalar-random-effects-1"></a><a class="docs-heading-anchor-permalink" href="#Simple,-scalar-random-effects" title="Permalink"></a></h3><p>A simple, scalar random effects term in a mixed-effects model formula is of the form <code>(1|G)</code>. All random effects terms end with <code>|G</code> where <code>G</code> is the <em>grouping factor</em> for the random effect. The name or, more generally the expression, <code>G</code>, should evaluate to a categorical array that has a distinct set of <em>levels</em>. The random effects are associated with the levels of the grouping factor.</p><p>A <em>scalar</em> random effect is, as the name implies, one scalar value for each level of the grouping factor. A <em>simple, scalar</em> random effects term is of the form, <code>(1|G)</code>. It corresponds to a shift in the intercept for each level of the grouping factor.</p><h3 id="Models-with-vector-valued-random-effects"><a class="docs-heading-anchor" href="#Models-with-vector-valued-random-effects">Models with vector-valued random effects</a><a id="Models-with-vector-valued-random-effects-1"></a><a class="docs-heading-anchor-permalink" href="#Models-with-vector-valued-random-effects" title="Permalink"></a></h3><p>The <em>sleepstudy</em> data are observations of reaction time, <code>reaction</code>, on several subjects, <code>subj</code>, after 0 to 9 days of sleep deprivation, <code>days</code>. A model with random intercepts and random slopes for each subject, allowing for within-subject correlation of the slope and intercept, is fit as</p><pre><code class="language-julia hljs">sleepstudy = MixedModelsDatasets.dataset(:sleepstudy)
fm2 = fit(MixedModel, @formula(reaction ~ 1 + days + (1 + days|subj)), sleepstudy)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + (1 + days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -875.9697  1751.9393  1763.9393  1764.4249  1783.0971

Variance components:
            Column    Variance Std.Dev.   Corr.
subj     (Intercept)  565.52071 23.78068
         days          32.68242  5.71685 +0.08
Residual              654.94015 25.59180
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
──────────────────────────────────────────────────
                Coef.  Std. Error      z  Pr(&gt;|z|)
──────────────────────────────────────────────────
(Intercept)  251.405      6.6323   37.91    &lt;1e-99
days          10.4673     1.50224   6.97    &lt;1e-11
──────────────────────────────────────────────────</code></pre><h3 id="Models-with-multiple,-scalar-random-effects-terms"><a class="docs-heading-anchor" href="#Models-with-multiple,-scalar-random-effects-terms">Models with multiple, scalar random-effects terms</a><a id="Models-with-multiple,-scalar-random-effects-terms-1"></a><a class="docs-heading-anchor-permalink" href="#Models-with-multiple,-scalar-random-effects-terms" title="Permalink"></a></h3><p>A model for the <em>Penicillin</em> data incorporates random effects for the plate, and for the sample. As every sample is used on every plate these two factors are <em>crossed</em>.</p><pre><code class="language-julia hljs">penicillin = MixedModelsDatasets.dataset(:penicillin)
fm3 = fit(MixedModel, @formula(diameter ~ 1 + (1|plate) + (1|sample)), penicillin)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 diameter ~ 1 + (1 | plate) + (1 | sample)
   logLik   -2 logLik     AIC       AICc        BIC    
  -166.0942   332.1883   340.1883   340.4761   352.0676

Variance components:
            Column   Variance Std.Dev. 
plate    (Intercept)  0.714993 0.845572
sample   (Intercept)  3.135139 1.770632
Residual              0.302426 0.549932
 Number of obs: 144; levels of grouping factors: 24, 6

  Fixed-effects parameters:
─────────────────────────────────────────────────
               Coef.  Std. Error      z  Pr(&gt;|z|)
─────────────────────────────────────────────────
(Intercept)  22.9722     0.74459  30.85    &lt;1e-99
─────────────────────────────────────────────────</code></pre><p>In contrast, the <code>cask</code> grouping factor is <em>nested</em> within the <code>batch</code> grouping factor in the <em>Pastes</em> data.</p><pre><code class="language-julia hljs">pastes = DataFrame(MixedModelsDatasets.dataset(:pastes))
describe(pastes)</code></pre><div><div style = "float: left;"><span>3×7 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">variable</th><th style = "text-align: left;">mean</th><th style = "text-align: left;">min</th><th style = "text-align: left;">median</th><th style = "text-align: left;">max</th><th style = "text-align: left;">nmissing</th><th style = "text-align: left;">eltype</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Symbol" style = "text-align: left;">Symbol</th><th title = "Union{Nothing, Float64}" style = "text-align: left;">Union…</th><th title = "Any" style = "text-align: left;">Any</th><th title = "Union{Nothing, Float64}" style = "text-align: left;">Union…</th><th title = "Any" style = "text-align: left;">Any</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "DataType" style = "text-align: left;">DataType</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">batch</td><td style = "font-style: italic; text-align: left;"></td><td style = "text-align: left;">A</td><td style = "font-style: italic; text-align: left;"></td><td style = "text-align: left;">J</td><td style = "text-align: right;">0</td><td style = "text-align: left;">String</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">cask</td><td style = "font-style: italic; text-align: left;"></td><td style = "text-align: left;">a</td><td style = "font-style: italic; text-align: left;"></td><td style = "text-align: left;">c</td><td style = "text-align: right;">0</td><td style = "text-align: left;">String</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: left;">strength</td><td style = "text-align: left;">60.0533</td><td style = "text-align: left;">54.2</td><td style = "text-align: left;">59.3</td><td style = "text-align: left;">66.0</td><td style = "text-align: right;">0</td><td style = "text-align: left;">Float64</td></tr></tbody></table></div><p>This can be expressed using the solidus (the &quot;<code>/</code>&quot; character) to separate grouping factors, read &quot;<code>cask</code> nested within <code>batch</code>&quot;:</p><pre><code class="language-julia hljs">fm4a = fit(MixedModel, @formula(strength ~ 1 + (1|batch/cask)), pastes)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 strength ~ 1 + (1 | batch) + (1 | batch &amp; cask)
   logLik   -2 logLik     AIC       AICc        BIC    
  -123.9972   247.9945   255.9945   256.7217   264.3718

Variance components:
                Column   Variance Std.Dev. 
batch &amp; cask (Intercept)  8.433674 2.904079
batch        (Intercept)  1.199152 1.095058
Residual                  0.678000 0.823407
 Number of obs: 60; levels of grouping factors: 30, 10

  Fixed-effects parameters:
─────────────────────────────────────────────────
               Coef.  Std. Error      z  Pr(&gt;|z|)
─────────────────────────────────────────────────
(Intercept)  60.0533    0.642135  93.52    &lt;1e-99
─────────────────────────────────────────────────</code></pre><p>If the levels of the inner grouping factor are unique across the levels of the outer grouping factor, then this nesting does not need to expressed explicitly in the model syntax. For example, defining <code>sample</code> to be the combination of <code>batch</code> and <code>cask</code>, yields a naming scheme where the nesting is apparent from the data even if not expressed in the formula. (That is, each level of <code>sample</code> occurs in conjunction with only one level of <code>batch</code>.) As such, this model is equivalent to the previous one.</p><pre><code class="language-julia hljs">pastes.sample = (string.(pastes.cask, &quot;&amp;&quot;,  pastes.batch))
fm4b = fit(MixedModel, @formula(strength ~ 1 + (1|sample) + (1|batch)), pastes)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 strength ~ 1 + (1 | sample) + (1 | batch)
   logLik   -2 logLik     AIC       AICc        BIC    
  -123.9972   247.9945   255.9945   256.7217   264.3718

Variance components:
            Column   Variance Std.Dev. 
sample   (Intercept)  8.433661 2.904077
batch    (Intercept)  1.199166 1.095064
Residual              0.678000 0.823407
 Number of obs: 60; levels of grouping factors: 30, 10

  Fixed-effects parameters:
─────────────────────────────────────────────────
               Coef.  Std. Error      z  Pr(&gt;|z|)
─────────────────────────────────────────────────
(Intercept)  60.0533    0.642136  93.52    &lt;1e-99
─────────────────────────────────────────────────</code></pre><p>In observational studies it is common to encounter <em>partially crossed</em> grouping factors. For example, the <em>InstEval</em> data are course evaluations by students, <code>s</code>, of instructors, <code>d</code>. Additional covariates include the academic department, <code>dept</code>, in which the course was given and <code>service</code>, whether or not it was a service course.</p><pre><code class="language-julia hljs">insteval = MixedModelsDatasets.dataset(:insteval)
fm5 = fit(MixedModel, @formula(y ~ 1 + service * dept + (1|s) + (1|d)), insteval)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 y ~ 1 + service + dept + service &amp; dept + (1 | s) + (1 | d)
    logLik     -2 logLik       AIC         AICc          BIC     
 -118792.7767  237585.5534  237647.5534  237647.5804  237932.8763

Variance components:
            Column   Variance Std.Dev. 
s        (Intercept)  0.105418 0.324681
d        (Intercept)  0.258417 0.508347
Residual              1.384728 1.176745
 Number of obs: 73421; levels of grouping factors: 2972, 1128

  Fixed-effects parameters:
────────────────────────────────────────────────────────────────
                              Coef.  Std. Error      z  Pr(&gt;|z|)
────────────────────────────────────────────────────────────────
(Intercept)              3.27628      0.0793647  41.28    &lt;1e-99
service: Y               0.0116045    0.0699321   0.17    0.8682
dept: D02               -0.0411091    0.120331   -0.34    0.7326
dept: D03                0.00967415   0.108411    0.09    0.9289
dept: D04                0.105017     0.0944965   1.11    0.2664
dept: D05                0.0828643    0.11148     0.74    0.4573
dept: D06               -0.01194      0.0978342  -0.12    0.9029
dept: D07                0.0992679    0.110598    0.90    0.3694
dept: D08                0.0575337    0.127935    0.45    0.6529
dept: D09               -0.00263179   0.107085   -0.02    0.9804
dept: D10               -0.223423     0.099838   -2.24    0.0252
dept: D11                0.0129817    0.110639    0.12    0.9066
dept: D12                0.00503826   0.0944243   0.05    0.9574
dept: D14                0.00508272   0.109041    0.05    0.9628
dept: D15               -0.0466719    0.101942   -0.46    0.6471
service: Y &amp; dept: D02  -0.144352     0.0929527  -1.55    0.1204
service: Y &amp; dept: D03   0.0174077    0.0927237   0.19    0.8511
service: Y &amp; dept: D04  -0.0381263    0.0810901  -0.47    0.6382
service: Y &amp; dept: D05   0.0596631    0.123952    0.48    0.6303
service: Y &amp; dept: D06  -0.254044     0.080781   -3.14    0.0017
service: Y &amp; dept: D07  -0.151634     0.11157    -1.36    0.1741
service: Y &amp; dept: D08   0.0508941    0.112189    0.45    0.6501
service: Y &amp; dept: D09  -0.259448     0.0899448  -2.88    0.0039
service: Y &amp; dept: D10   0.25907      0.11137     2.33    0.0200
service: Y &amp; dept: D11  -0.276577     0.0819621  -3.37    0.0007
service: Y &amp; dept: D12  -0.041849     0.0792928  -0.53    0.5977
service: Y &amp; dept: D14  -0.256742     0.0931016  -2.76    0.0058
service: Y &amp; dept: D15   0.24042      0.0982071   2.45    0.0144
────────────────────────────────────────────────────────────────</code></pre><h3 id="Simplifying-the-random-effect-correlation-structure"><a class="docs-heading-anchor" href="#Simplifying-the-random-effect-correlation-structure">Simplifying the random effect correlation structure</a><a id="Simplifying-the-random-effect-correlation-structure-1"></a><a class="docs-heading-anchor-permalink" href="#Simplifying-the-random-effect-correlation-structure" title="Permalink"></a></h3><p><code>MixedModels.jl</code> estimates not only the <em>variance</em> of the effects for each random effect level, but also the <em>correlation</em> between the random effects for different predictors. So, for the model of the <em>sleepstudy</em> data above, one of the parameters that is estimated is the correlation between each subject&#39;s random intercept (i.e., their baseline reaction time) and slope (i.e., their particular change in reaction time per day of sleep deprivation). In some cases, you may wish to simplify the random effects structure by removing these correlation parameters. This often arises when there are many random effects you want to estimate (as is common in psychological experiments with many conditions and covariates), since the number of random effects parameters increases as the square of the number of predictors, making these models difficult to estimate from limited data.</p><p>The special syntax <code>zerocorr</code> can be applied to individual random effects terms inside the <code>@formula</code>:</p><pre><code class="language-julia hljs">fm2zerocorr_fm = fit(MixedModel, @formula(reaction ~ 1 + days + zerocorr(1 + days|subj)), sleepstudy)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + zerocorr(1 + days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -876.0016  1752.0033  1762.0033  1762.3481  1777.9680

Variance components:
            Column   Variance Std.Dev.  Corr.
subj     (Intercept)  584.2547 24.1714
         days          33.6330  5.7994   .  
Residual              653.1157 25.5561
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
──────────────────────────────────────────────────
                Coef.  Std. Error      z  Pr(&gt;|z|)
──────────────────────────────────────────────────
(Intercept)  251.405      6.70769  37.48    &lt;1e-99
days          10.4673     1.51931   6.89    &lt;1e-11
──────────────────────────────────────────────────</code></pre><p>Alternatively, correlations between parameters can be removed by including them as separate random effects terms:</p><pre><code class="language-julia hljs">fit(MixedModel, @formula(reaction ~ 1 + days + (1|subj) + (days|subj)), sleepstudy)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + (1 | subj) + (days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -876.0016  1752.0033  1762.0033  1762.3481  1777.9680

Variance components:
            Column   Variance Std.Dev.  Corr.
subj     (Intercept)  584.2547 24.1714
         days          33.6330  5.7994   .  
Residual              653.1157 25.5561
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
──────────────────────────────────────────────────
                Coef.  Std. Error      z  Pr(&gt;|z|)
──────────────────────────────────────────────────
(Intercept)  251.405      6.70769  37.48    &lt;1e-99
days          10.4673     1.51931   6.89    &lt;1e-11
──────────────────────────────────────────────────</code></pre><p>Finally, for predictors that are categorical, <code>MixedModels.jl</code> will estimate correlations between each level. Notice the large number of correlation parameters if we treat <code>days</code> as a categorical variable by giving it contrasts:</p><pre><code class="language-julia hljs">fit(MixedModel, @formula(reaction ~ 1 + days + (1 + days|subj)), sleepstudy,
    contrasts = Dict(:days =&gt; DummyCoding()))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + (1 + days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -805.3991  1610.7982  1742.7982  1821.0637  1953.5334

Variance components:
            Column    Variance  Std.Dev.   Corr.
subj     (Intercept)   955.98284 30.91897
         days: 1       497.94627 22.31471 -0.30
         days: 2       917.16373 30.28471 -0.57 +0.75
         days: 3      1269.62101 35.63174 -0.37 +0.72 +0.87
         days: 4      1487.38580 38.56664 -0.32 +0.59 +0.67 +0.91
         days: 5      2299.83989 47.95665 -0.25 +0.46 +0.45 +0.70 +0.85
         days: 6      3856.04148 62.09703 -0.28 +0.30 +0.48 +0.70 +0.77 +0.75
         days: 7      1809.67762 42.54031 -0.16 +0.22 +0.47 +0.50 +0.63 +0.64 +0.71
         days: 8      3157.68383 56.19327 -0.20 +0.29 +0.36 +0.56 +0.73 +0.90 +0.73 +0.74
         days: 9      3078.27872 55.48224 +0.05 +0.26 +0.16 +0.38 +0.59 +0.78 +0.38 +0.53 +0.85
Residual                18.89497  4.34683
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
───────────────────────────────────────────────────
                 Coef.  Std. Error      z  Pr(&gt;|z|)
───────────────────────────────────────────────────
(Intercept)  256.652       7.35934  34.87    &lt;1e-99
days: 1        7.84395     5.45556   1.44    0.1505
days: 2        8.71009     7.28375   1.20    0.2318
days: 3       26.3402      8.52255   3.09    0.0020
days: 4       31.9976      9.205     3.48    0.0005
days: 5       51.8666     11.396     4.55    &lt;1e-05
days: 6       55.5264     14.708     3.78    0.0002
days: 7       62.0988     10.131     6.13    &lt;1e-09
days: 8       79.9777     13.3239    6.00    &lt;1e-08
days: 9       94.1994     13.1573    7.16    &lt;1e-12
───────────────────────────────────────────────────</code></pre><p>Separating the <code>1</code> and <code>days</code> random effects into separate terms removes the correlations between the intercept and the levels of <code>days</code>, but not between the levels themselves:</p><pre><code class="language-julia hljs">fit(MixedModel, @formula(reaction ~ 1 + days + (1|subj) + (days|subj)), sleepstudy,
    contrasts = Dict(:days =&gt; DummyCoding()))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + (1 | subj) + (days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -815.9006  1631.8012  1745.8012  1799.9980  1927.7998

Variance components:
            Column    Variance  Std.Dev.   Corr.
subj     (Intercept)   917.91162 30.29706
         days: 1       449.11133 21.19225   .  
         days: 2       842.56594 29.02699   .   +0.75
         days: 3      1202.17703 34.67242   .   +0.72 +0.88
         days: 4      1421.15767 37.69824   .   +0.58 +0.66 +0.92
         days: 5      2232.13683 47.24550   .   +0.45 +0.44 +0.70 +0.85
         days: 6      3777.16785 61.45867   .   +0.28 +0.48 +0.70 +0.78 +0.75
         days: 7      1756.91352 41.91555   .   +0.20 +0.46 +0.49 +0.62 +0.64 +0.71
         days: 8      3090.59943 55.59316   .   +0.27 +0.35 +0.56 +0.73 +0.90 +0.73 +0.74
         days: 9      3048.06900 55.20932   .   +0.25 +0.15 +0.38 +0.59 +0.78 +0.38 +0.53 +0.86
Residual                35.64042  5.96996
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
───────────────────────────────────────────────────
                 Coef.  Std. Error      z  Pr(&gt;|z|)
───────────────────────────────────────────────────
(Intercept)  256.652       7.2784   35.26    &lt;1e-99
days: 1        7.84395     5.37686   1.46    0.1446
days: 2        8.71009     7.12526   1.22    0.2215
days: 3       26.3402      8.41116   3.13    0.0017
days: 4       31.9976      9.10567   3.51    0.0004
days: 5       51.8666     11.3123    4.58    &lt;1e-05
days: 6       55.5264     14.622     3.80    0.0001
days: 7       62.0988     10.078     6.16    &lt;1e-09
days: 8       79.9777     13.2537    6.03    &lt;1e-08
days: 9       94.1994     13.1642    7.16    &lt;1e-12
───────────────────────────────────────────────────</code></pre><p>(Notice that the variance component for <code>days: 1</code> is estimated as zero, so the correlations for this component are undefined and expressed as <code>NaN</code>, not a number.)</p><p>An alternative is to force all the levels of <code>days</code> as indicators using <code>fulldummy</code> encoding.</p><pre><code class="language-julia hljs">fit(MixedModel, @formula(reaction ~ 1 + days + (1 + fulldummy(days)|subj)), sleepstudy,
    contrasts = Dict(:days =&gt; DummyCoding()))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + (1 + days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -805.3991  1610.7982  1764.7982  1882.5629  2010.6559

Variance components:
            Column    Variance  Std.Dev.   Corr.
subj     (Intercept)   640.46761 25.30746
         days: 0       526.67309 22.94936 -0.18
         days: 1       653.73096 25.56816 -0.20 +0.58
         days: 2       461.88299 21.49146 -0.28 +0.07 +0.65
         days: 3       417.46155 20.43188 +0.34 -0.35 +0.43 +0.64
         days: 4       459.57667 21.43774 +0.54 -0.51 +0.12 +0.08 +0.72
         days: 5      1266.35955 35.58595 +0.34 -0.31 +0.06 -0.11 +0.35 +0.71
         days: 6      2424.54679 49.23969 +0.28 -0.40 -0.18 -0.03 +0.40 +0.59 +0.58
         days: 7      1297.44409 36.02005 +0.23 +0.01 +0.04 +0.16 +0.11 +0.33 +0.42 +0.51
         days: 8      2049.38910 45.27018 +0.31 -0.28 -0.10 -0.17 +0.16 +0.52 +0.84 +0.57 +0.59
         days: 9      2515.80443 50.15780 +0.42 -0.02 +0.09 -0.21 +0.04 +0.43 +0.71 +0.13 +0.39 +0.81
Residual                19.14750  4.37579
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
───────────────────────────────────────────────────
                 Coef.  Std. Error      z  Pr(&gt;|z|)
───────────────────────────────────────────────────
(Intercept)  256.652       7.35899  34.88    &lt;1e-99
days: 1        7.84395     5.45632   1.44    0.1506
days: 2        8.71009     7.28463   1.20    0.2318
days: 3       26.3402      8.52439   3.09    0.0020
days: 4       31.9976      9.20677   3.48    0.0005
days: 5       51.8667     11.397     4.55    &lt;1e-05
days: 6       55.5265     14.7079    3.78    0.0002
days: 7       62.0988     10.1311    6.13    &lt;1e-09
days: 8       79.9777     13.3241    6.00    &lt;1e-08
days: 9       94.1994     13.1575    7.16    &lt;1e-12
───────────────────────────────────────────────────</code></pre><p>This fit produces a better fit as measured by the objective (negative twice the log-likelihood is 1610.8) but at the expense of adding many more parameters to the model. As a result, model comparison criteria such, as <code>AIC</code> and <code>BIC</code>, are inflated.</p><p>But using <code>zerocorr</code> on the individual terms does remove the correlations between the levels:</p><pre><code class="language-julia hljs">fit(MixedModel, @formula(reaction ~ 1 + days + zerocorr(1 + days|subj)), sleepstudy,
    contrasts = Dict(:days =&gt; DummyCoding()))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + zerocorr(1 + days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -882.9138  1765.8276  1807.8276  1813.6757  1874.8797

Variance components:
            Column    Variance Std.Dev.  Corr.
subj     (Intercept)   958.5364 30.9602
         days: 1         0.0000  0.0000   .  
         days: 2         0.0000  0.0000   .     .  
         days: 3         0.0000  0.0000   .     .     .  
         days: 4         0.0000  0.0000   .     .     .     .  
         days: 5       519.6046 22.7948   .     .     .     .     .  
         days: 6      1704.0493 41.2801   .     .     .     .     .     .  
         days: 7       608.7797 24.6735   .     .     .     .     .     .     .  
         days: 8      1273.0916 35.6804   .     .     .     .     .     .     .     .  
         days: 9      1754.0795 41.8817   .     .     .     .     .     .     .     .     .  
Residual               434.8566 20.8532
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
───────────────────────────────────────────────────
                 Coef.  Std. Error      z  Pr(&gt;|z|)
───────────────────────────────────────────────────
(Intercept)  256.652       8.79834  29.17    &lt;1e-99
days: 1        7.84395     6.95107   1.13    0.2591
days: 2        8.71009     6.95107   1.25    0.2102
days: 3       26.3402      6.95107   3.79    0.0002
days: 4       31.9976      6.95107   4.60    &lt;1e-05
days: 5       51.8666      8.78546   5.90    &lt;1e-08
days: 6       55.5264     11.9577    4.64    &lt;1e-05
days: 7       62.0988      9.06303   6.85    &lt;1e-11
days: 8       79.9777     10.9108    7.33    &lt;1e-12
days: 9       94.1994     12.0734    7.80    &lt;1e-14
───────────────────────────────────────────────────</code></pre><pre><code class="language-julia hljs">fit(MixedModel, @formula(reaction ~ 1 + days + (1|subj) + zerocorr(days|subj)), sleepstudy,
    contrasts = Dict(:days =&gt; DummyCoding()))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + (1 | subj) + zerocorr(days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -882.9138  1765.8276  1807.8276  1813.6757  1874.8797

Variance components:
            Column    Variance Std.Dev.  Corr.
subj     (Intercept)   958.5364 30.9602
         days: 1         0.0000  0.0000   .  
         days: 2         0.0000  0.0000   .     .  
         days: 3         0.0000  0.0000   .     .     .  
         days: 4         0.0000  0.0000   .     .     .     .  
         days: 5       519.6046 22.7948   .     .     .     .     .  
         days: 6      1704.0493 41.2801   .     .     .     .     .     .  
         days: 7       608.7797 24.6735   .     .     .     .     .     .     .  
         days: 8      1273.0916 35.6804   .     .     .     .     .     .     .     .  
         days: 9      1754.0795 41.8817   .     .     .     .     .     .     .     .     .  
Residual               434.8566 20.8532
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
───────────────────────────────────────────────────
                 Coef.  Std. Error      z  Pr(&gt;|z|)
───────────────────────────────────────────────────
(Intercept)  256.652       8.79834  29.17    &lt;1e-99
days: 1        7.84395     6.95107   1.13    0.2591
days: 2        8.71009     6.95107   1.25    0.2102
days: 3       26.3402      6.95107   3.79    0.0002
days: 4       31.9976      6.95107   4.60    &lt;1e-05
days: 5       51.8666      8.78546   5.90    &lt;1e-08
days: 6       55.5264     11.9577    4.64    &lt;1e-05
days: 7       62.0988      9.06303   6.85    &lt;1e-11
days: 8       79.9777     10.9108    7.33    &lt;1e-12
days: 9       94.1994     12.0734    7.80    &lt;1e-14
───────────────────────────────────────────────────</code></pre><pre><code class="language-julia hljs">fit(MixedModel, @formula(reaction ~ 1 + days + zerocorr(1 + fulldummy(days)|subj)), sleepstudy,
    contrasts = Dict(:days =&gt; DummyCoding()))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + zerocorr(1 + days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -878.9843  1757.9686  1801.9686  1808.4145  1872.2137

Variance components:
            Column     Variance   Std.Dev.   Corr.
subj     (Intercept)  1135.145912 33.691927
         days: 0       776.498722 27.865727   .  
         days: 1       358.222782 18.926774   .     .  
         days: 2       221.696296 14.889469   .     .     .  
         days: 3         0.601244  0.775399   .     .     .     .  
         days: 4        44.953181  6.704713   .     .     .     .     .  
         days: 5       670.793401 25.899680   .     .     .     .     .     .  
         days: 6      1740.364634 41.717678   .     .     .     .     .     .     .  
         days: 7       909.218702 30.153254   .     .     .     .     .     .     .     .  
         days: 8      1458.403125 38.189045   .     .     .     .     .     .     .     .     .  
         days: 9      2028.558005 45.039516   .     .     .     .     .     .     .     .     .     .  
Residual               180.399835 13.431301
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
───────────────────────────────────────────────────
                 Coef.  Std. Error      z  Pr(&gt;|z|)
───────────────────────────────────────────────────
(Intercept)  256.652      10.7808   23.81    &lt;1e-99
days: 1        7.84395     9.11507   0.86    0.3895
days: 2        8.71009     8.68906   1.00    0.3161
days: 3       26.3402      7.95089   3.31    0.0009
days: 4       31.9976      8.10436   3.95    &lt;1e-04
days: 5       51.8666     10.0225    5.18    &lt;1e-06
days: 6       55.5265     12.644     4.39    &lt;1e-04
days: 7       62.0988     10.6628    5.82    &lt;1e-08
days: 8       79.9777     12.0086    6.66    &lt;1e-10
days: 9       94.1994     13.262     7.10    &lt;1e-11
───────────────────────────────────────────────────</code></pre><h2 id="Fitting-generalized-linear-mixed-models"><a class="docs-heading-anchor" href="#Fitting-generalized-linear-mixed-models">Fitting generalized linear mixed models</a><a id="Fitting-generalized-linear-mixed-models-1"></a><a class="docs-heading-anchor-permalink" href="#Fitting-generalized-linear-mixed-models" title="Permalink"></a></h2><p>To create a GLMM representation, the distribution family for the response, and possibly the link function, must be specified. You can either use <code>fit(MixedModel, ...)</code> or <code>glmm(...)</code> to fit the model. For instance:</p><pre><code class="language-julia hljs">verbagg = MixedModelsDatasets.dataset(:verbagg)
verbaggform = @formula(r2 ~ 1 + anger + gender + btype + situ + mode + (1|subj) + (1|item));
gm1 = fit(MixedModel, verbaggform, verbagg, Bernoulli())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 1)
  r2 ~ 1 + anger + gender + btype + situ + mode + (1 | subj) + (1 | item)
  Distribution: Bernoulli{Float64}
  Link: LogitLink()

   logLik    deviance     AIC       AICc        BIC    
 -4067.9164  8135.8329  8153.8329  8153.8566  8216.2370

Variance components:
        Column   Variance Std.Dev. 
subj (Intercept)  1.793397 1.339178
item (Intercept)  0.117135 0.342251

 Number of obs: 7584; levels of grouping factors: 316, 24

Fixed-effects parameters:
──────────────────────────────────────────────────────
                   Coef.  Std. Error       z  Pr(&gt;|z|)
──────────────────────────────────────────────────────
(Intercept)   -0.153745    0.385211    -0.40    0.6898
anger          0.0574292   0.0167524    3.43    0.0006
gender: M      0.320535    0.191203     1.68    0.0937
btype: scold  -1.05969     0.184149    -5.75    &lt;1e-08
btype: shout  -2.10385     0.186508   -11.28    &lt;1e-28
situ: self    -1.05436     0.151187    -6.97    &lt;1e-11
mode: want     0.707005    0.151        4.68    &lt;1e-05
──────────────────────────────────────────────────────</code></pre><p>The model can also be fit as</p><pre><code class="language-julia hljs">gm1 = glmm(verbaggform, verbagg, Bernoulli())</code></pre><table><tr><th align="left"></th><th align="right">Est.</th><th align="right">SE</th><th align="right">z</th><th align="right">p</th><th align="right">σ_subj</th><th align="right">σ_item</th></tr><tr><td align="left">&#40;Intercept&#41;</td><td align="right">-0.1537</td><td align="right">0.3852</td><td align="right">-0.40</td><td align="right">0.6898</td><td align="right">1.3392</td><td align="right">0.3423</td></tr><tr><td align="left">anger</td><td align="right">0.0574</td><td align="right">0.0168</td><td align="right">3.43</td><td align="right">0.0006</td><td align="right"> </td><td align="right"> </td></tr><tr><td align="left">gender: M</td><td align="right">0.3205</td><td align="right">0.1912</td><td align="right">1.68</td><td align="right">0.0937</td><td align="right"> </td><td align="right"> </td></tr><tr><td align="left">btype: scold</td><td align="right">-1.0597</td><td align="right">0.1841</td><td align="right">-5.75</td><td align="right">&lt;1e-08</td><td align="right"> </td><td align="right"> </td></tr><tr><td align="left">btype: shout</td><td align="right">-2.1039</td><td align="right">0.1865</td><td align="right">-11.28</td><td align="right">&lt;1e-28</td><td align="right"> </td><td align="right"> </td></tr><tr><td align="left">situ: self</td><td align="right">-1.0544</td><td align="right">0.1512</td><td align="right">-6.97</td><td align="right">&lt;1e-11</td><td align="right"> </td><td align="right"> </td></tr><tr><td align="left">mode: want</td><td align="right">0.7070</td><td align="right">0.1510</td><td align="right">4.68</td><td align="right">&lt;1e-05</td><td align="right"> </td><td align="right"> </td></tr></table>
<p>The canonical link, which is <code>LogitLink</code> for the <code>Bernoulli</code> distribution, is used if no explicit link is specified.</p><p>Note that, in keeping with convention in the <a href="https://github.com/JuliaStats/GLM.jl"><code>GLM</code> package</a>, the distribution family for a binary (i.e. 0/1) response is the <code>Bernoulli</code> distribution. The <code>Binomial</code> distribution is only used when the response is the fraction of trials returning a positive, in which case the number of trials must be specified as the case weights.</p><h3 id="Optional-arguments-to-fit"><a class="docs-heading-anchor" href="#Optional-arguments-to-fit">Optional arguments to fit</a><a id="Optional-arguments-to-fit-1"></a><a class="docs-heading-anchor-permalink" href="#Optional-arguments-to-fit" title="Permalink"></a></h3><p>An alternative approach is to create the <code>GeneralizedLinearMixedModel</code> object then call <code>fit!</code> on it. The optional arguments <code>fast</code> and/or <code>nAGQ</code> can be passed to the optimization process via both <code>fit</code> and <code>fit!</code> (i.e these optimization settings are not used nor recognized when constructing the model).</p><p>As the name implies, <code>fast=true</code>, provides a faster but somewhat less accurate fit. These fits may suffice for model comparisons.</p><pre><code class="language-julia hljs">gm1a = fit(MixedModel, verbaggform, verbagg, Bernoulli(), fast = true)
deviance(gm1a) - deviance(gm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.3380123026227011</code></pre><pre><code class="language-julia hljs">@benchmark fit(MixedModel, $verbaggform, $verbagg, Bernoulli())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">BenchmarkTools.Trial: 2 samples with 1 evaluation per sample.
 Range <span class="sgr90">(</span><span class="sgr36"><span class="sgr1">min</span></span> … <span class="sgr35">max</span><span class="sgr90">):  </span><span class="sgr36"><span class="sgr1">4.053 s</span></span> … <span class="sgr35">  4.080 s</span>  <span class="sgr90">┊</span> GC <span class="sgr90">(</span>min … max<span class="sgr90">): </span>0.00% … 0.09%
 Time  <span class="sgr90">(</span><span class="sgr34"><span class="sgr1">median</span></span><span class="sgr90">):     </span><span class="sgr34"><span class="sgr1">4.067 s              </span></span><span class="sgr90">┊</span> GC <span class="sgr90">(</span>median<span class="sgr90">):    </span>0.04%
 Time  <span class="sgr90">(</span><span class="sgr32"><span class="sgr1">mean</span></span> ± <span class="sgr32">σ</span><span class="sgr90">):   </span><span class="sgr32"><span class="sgr1">4.067 s</span></span> ± <span class="sgr32">18.536 ms</span>  <span class="sgr90">┊</span> GC <span class="sgr90">(</span>mean ± σ<span class="sgr90">):  </span>0.04% ± 0.06%

  <span class="sgr34">█</span>                           <span class="sgr32"> </span>                           █  
  <span class="sgr34">█</span>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁<span class="sgr32">▁</span>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█ ▁
  4.05 s<span class="sgr90">         Histogram: frequency by time</span>        4.08 s <span class="sgr1">&lt;</span>

 Memory estimate<span class="sgr90">: </span><span class="sgr33">64.69 MiB</span>, allocs estimate<span class="sgr90">: </span><span class="sgr33">655664</span>.</code></pre><pre><code class="language-julia hljs">@benchmark fit(MixedModel, $verbaggform, $verbagg, Bernoulli(), fast = true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">BenchmarkTools.Trial: 29 samples with 1 evaluation per sample.
 Range <span class="sgr90">(</span><span class="sgr36"><span class="sgr1">min</span></span> … <span class="sgr35">max</span><span class="sgr90">):  </span><span class="sgr36"><span class="sgr1">175.645 ms</span></span> … <span class="sgr35">182.141 ms</span>  <span class="sgr90">┊</span> GC <span class="sgr90">(</span>min … max<span class="sgr90">): </span>0.00% … 1.23%
 Time  <span class="sgr90">(</span><span class="sgr34"><span class="sgr1">median</span></span><span class="sgr90">):     </span><span class="sgr34"><span class="sgr1">177.476 ms               </span></span><span class="sgr90">┊</span> GC <span class="sgr90">(</span>median<span class="sgr90">):    </span>0.00%
 Time  <span class="sgr90">(</span><span class="sgr32"><span class="sgr1">mean</span></span> ± <span class="sgr32">σ</span><span class="sgr90">):   </span><span class="sgr32"><span class="sgr1">177.876 ms</span></span> ± <span class="sgr32">  1.699 ms</span>  <span class="sgr90">┊</span> GC <span class="sgr90">(</span>mean ± σ<span class="sgr90">):  </span>0.14% ± 0.41%

   ▃      ▃  ▃   █<span class="sgr34"> </span>▃   <span class="sgr32"> </span>                                         
  ▇█▁▁▁▁▁▁█▇▇█▇▇▁█<span class="sgr34">▁</span>█▇▇▇<span class="sgr32">▇</span>▁▁▇▇▇▁▁▇▁▁▁▇▁▁▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▇▁▇ ▁
  176 ms<span class="sgr90">           Histogram: frequency by time</span>          182 ms <span class="sgr1">&lt;</span>

 Memory estimate<span class="sgr90">: </span><span class="sgr33">10.73 MiB</span>, allocs estimate<span class="sgr90">: </span><span class="sgr33">77628</span>.</code></pre><p>The optional argument <code>nAGQ=k</code> causes evaluation of the deviance function to use a <code>k</code> point adaptive Gauss-Hermite quadrature rule. This method only applies to models with a single, simple, scalar random-effects term, such as</p><pre><code class="language-julia hljs">contraception = MixedModelsDatasets.dataset(:contra)
contraform = @formula(use ~ 1 + age + abs2(age) + livch + urban + (1|dist));
bernoulli = Bernoulli()
deviances = Dict{Symbol,Float64}()
b = @benchmarkable deviances[:default] = deviance(fit(MixedModel, $contraform, $contraception, $bernoulli));
run(b)
b = @benchmarkable deviances[:fast] = deviance(fit(MixedModel, $contraform, $contraception, $bernoulli, fast = true));
run(b)
b = @benchmarkable deviances[:nAGQ] = deviance(fit(MixedModel, $contraform, $contraception, $bernoulli, nAGQ=9));
run(b)
b = @benchmarkable deviances[:nAGQ_fast] = deviance(fit(MixedModel, $contraform, $contraception, $bernoulli, nAGQ=9, fast=true));
run(b)
sort(deviances)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">OrderedCollections.OrderedDict{Symbol, Float64} with 4 entries:
  :default   =&gt; 2372.73
  :fast      =&gt; 2372.78
  :nAGQ      =&gt; 2372.46
  :nAGQ_fast =&gt; 2372.51</code></pre><h1 id="Extractor-functions"><a class="docs-heading-anchor" href="#Extractor-functions">Extractor functions</a><a id="Extractor-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Extractor-functions" title="Permalink"></a></h1><p><code>LinearMixedModel</code> and <code>GeneralizedLinearMixedModel</code> are subtypes of <code>StatsAPI.RegressionModel</code> which, in turn, is a subtype of <code>StatsBase.StatisticalModel</code>. Many of the generic extractors defined in the <code>StatsBase</code> package have methods for these models.</p><h2 id="Model-fit-statistics"><a class="docs-heading-anchor" href="#Model-fit-statistics">Model-fit statistics</a><a id="Model-fit-statistics-1"></a><a class="docs-heading-anchor-permalink" href="#Model-fit-statistics" title="Permalink"></a></h2><p>The statistics describing the quality of the model fit include</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.loglikelihood" href="#StatsAPI.loglikelihood"><code>StatsAPI.loglikelihood</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">loglikelihood(model::StatisticalModel)
loglikelihood(model::StatisticalModel, observation)</code></pre><p>Return the log-likelihood of the model.</p><p>With an <code>observation</code> argument, return the contribution of <code>observation</code> to the log-likelihood of <code>model</code>.</p><p>If <code>observation</code> is a <code>Colon</code>, return a vector of each observation&#39;s contribution to the log-likelihood of the model. In other words, this is the vector of the pointwise log-likelihood contributions.</p><p>In general, <code>sum(loglikehood(model, :)) == loglikelihood(model)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsAPI.jl/blob/v1.7.1/src/statisticalmodel.jl#L68-L82">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.aic" href="#StatsAPI.aic"><code>StatsAPI.aic</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">aic(model::StatisticalModel)</code></pre><p>Akaike&#39;s Information Criterion, defined as <span>$-2 \log L + 2k$</span>, with <span>$L$</span> the likelihood of the model, and <code>k</code> its number of consumed degrees of freedom (as returned by <a href="#StatsAPI.dof"><code>dof</code></a>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsAPI.jl/blob/v1.7.1/src/statisticalmodel.jl#L182-L188">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.bic" href="#StatsAPI.bic"><code>StatsAPI.bic</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">bic(model::StatisticalModel)</code></pre><p>Bayesian Information Criterion, defined as <span>$-2 \log L + k \log n$</span>, with <span>$L$</span> the likelihood of the model,  <span>$k$</span> its number of consumed degrees of freedom (as returned by <a href="#StatsAPI.dof"><code>dof</code></a>), and <span>$n$</span> the number of observations (as returned by <a href="#StatsAPI.nobs"><code>nobs</code></a>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsAPI.jl/blob/v1.7.1/src/statisticalmodel.jl#L205-L212">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.dof" href="#StatsAPI.dof"><code>StatsAPI.dof</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">dof(model::StatisticalModel)</code></pre><p>Return the number of degrees of freedom consumed in the model, including when applicable the intercept and the distribution&#39;s dispersion parameter.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsAPI.jl/blob/v1.7.1/src/statisticalmodel.jl#L114-L119">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.nobs" href="#StatsAPI.nobs"><code>StatsAPI.nobs</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">nobs(model::StatisticalModel)</code></pre><p>Return the number of independent observations on which the model was fitted. Be careful when using this information, as the definition of an independent observation may vary depending on the model, on the format used to pass the data, on the sampling plan (if specified), etc.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsAPI.jl/blob/v1.7.1/src/statisticalmodel.jl#L104-L111">source</a></section></article><pre><code class="language-julia hljs">loglikelihood(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">-163.66352994056336</code></pre><pre><code class="language-julia hljs">aic(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">333.32705988112673</code></pre><pre><code class="language-julia hljs">bic(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">337.5306520261132</code></pre><pre><code class="language-julia hljs">dof(fm1)   # 1 fixed effect, 2 variances</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3</code></pre><pre><code class="language-julia hljs">nobs(fm1)  # 30 observations</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">30</code></pre><pre><code class="language-julia hljs">loglikelihood(gm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">-4067.916429701673</code></pre><p>In general the <a href="https://en.wikipedia.org/wiki/Deviance_(statistics)"><code>deviance</code></a> of a statistical model fit is negative twice the log-likelihood adjusting for the saturated model.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.deviance-Tuple{StatisticalModel}" href="#StatsAPI.deviance-Tuple{StatisticalModel}"><code>StatsAPI.deviance</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">deviance(m::GeneralizedLinearMixedModel{T}, nAGQ=1)::T where {T}</code></pre><p>Return the deviance of <code>m</code> evaluated by the Laplace approximation (<code>nAGQ=1</code>) or <code>nAGQ</code>-point adaptive Gauss-Hermite quadrature.</p><p>If the distribution <code>D</code> does not have a scale parameter the Laplace approximation is the squared length of the conditional modes, <span>$u$</span>, plus the determinant of <span>$Λ&#39;Z&#39;WZΛ + I$</span>, plus the sum of the squared deviance residuals.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/generalizedlinearmixedmodel.jl#L74-L83">source</a></section></article><p>Because it is not clear what the saturated model corresponding to a particular <code>LinearMixedModel</code> should be, negative twice the log-likelihood is called the <code>objective</code>.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MixedModels.objective" href="#MixedModels.objective"><code>MixedModels.objective</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">objective(m::LinearMixedModel)</code></pre><p>Return negative twice the log-likelihood of model <code>m</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/linearmixedmodel.jl#L806-L810">source</a></section></article><p>This value is also accessible as the <code>deviance</code> but the user should bear in mind that this doesn&#39;t have all the properties of a deviance which is corrected for the saturated model. For example, it is not necessarily non-negative.</p><pre><code class="language-julia hljs">objective(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">327.32705988112673</code></pre><pre><code class="language-julia hljs">deviance(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">327.32705988112673</code></pre><p>The value optimized when fitting a <code>GeneralizedLinearMixedModel</code> is the Laplace approximation to the deviance or an adaptive Gauss-Hermite evaluation.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MixedModels.deviance!" href="#MixedModels.deviance!"><code>MixedModels.deviance!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">deviance!(m::GeneralizedLinearMixedModel, nAGQ=1)</code></pre><p>Update <code>m.η</code>, <code>m.μ</code>, etc., install the working response and working weights in <code>m.LMM</code>, update <code>m.LMM.A</code> and <code>m.LMM.R</code>, then evaluate the <code>deviance</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/generalizedlinearmixedmodel.jl#L134-L139">source</a></section></article><pre><code class="language-julia hljs">MixedModels.deviance!(gm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">8135.832859403364</code></pre><h2 id="Fixed-effects-parameter-estimates"><a class="docs-heading-anchor" href="#Fixed-effects-parameter-estimates">Fixed-effects parameter estimates</a><a id="Fixed-effects-parameter-estimates-1"></a><a class="docs-heading-anchor-permalink" href="#Fixed-effects-parameter-estimates" title="Permalink"></a></h2><p>The <code>coef</code> and <code>fixef</code> extractors both return the maximum likelihood estimates of the fixed-effects coefficients. They differ in their behavior in the rank-deficient case. The associated <code>coefnames</code> and <code>fixefnames</code> return the corresponding coefficient names.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.coef" href="#StatsAPI.coef"><code>StatsAPI.coef</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">coef(model::StatisticalModel)</code></pre><p>Return the coefficients of the model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsAPI.jl/blob/v1.7.1/src/statisticalmodel.jl#L8-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.coefnames" href="#StatsAPI.coefnames"><code>StatsAPI.coefnames</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">coefnames(model::StatisticalModel)</code></pre><p>Return the names of the coefficients.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsAPI.jl/blob/v1.7.1/src/statisticalmodel.jl#L15-L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MixedModels.fixef" href="#MixedModels.fixef"><code>MixedModels.fixef</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fixef(m::MixedModel)</code></pre><p>Return the fixed-effects parameter vector estimate of <code>m</code>.</p><p>In the rank-deficient case the truncated parameter vector, of length <code>rank(m)</code> is returned. This is unlike <code>coef</code> which always returns a vector whose length matches the number of columns in <code>X</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/linearmixedmodel.jl#L562-L570">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MixedModels.fixefnames" href="#MixedModels.fixefnames"><code>MixedModels.fixefnames</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fixefnames(m::MixedModel)</code></pre><p>Return a (permuted and truncated in the rank-deficient case) vector of coefficient names.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/linearmixedmodel.jl#L573-L577">source</a></section></article><pre><code class="language-julia hljs">coef(fm1)
coefnames(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{String}:
 &quot;(Intercept)&quot;</code></pre><pre><code class="language-julia hljs">fixef(fm1)
fixefnames(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{String}:
 &quot;(Intercept)&quot;</code></pre><p>An alternative extractor for the fixed-effects coefficient is the <code>β</code> property. Properties whose names are Greek letters usually have an alternative spelling, which is the name of the Greek letter.</p><pre><code class="language-julia hljs">fm1.β</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 1527.5000000000011</code></pre><pre><code class="language-julia hljs">fm1.beta</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 1527.5000000000011</code></pre><pre><code class="language-julia hljs">gm1.β</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">7-element Vector{Float64}:
 -0.15374521706254418
  0.057429184648104196
  0.32053477387095086
 -1.059693575252348
 -2.103852401715679
 -1.0543587111038337
  0.7070045757873128</code></pre><p>A full list of property names is returned by <code>propertynames</code></p><pre><code class="language-julia hljs">propertynames(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(:formula, :reterms, :Xymat, :feterm, :sqrtwts, :parmap, :dims, :A, :L, :optsum, :θ, :theta, :β, :beta, :βs, :betas, :λ, :lambda, :stderror, :σ, :sigma, :σs, :sigmas, :σρs, :sigmarhos, :b, :u, :X, :y, :corr, :vcov, :PCA, :rePCA, :objective, :pvalues)</code></pre><pre><code class="language-julia hljs">propertynames(gm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(:A, :L, :theta, :beta, :coef, :λ, :σ, :sigma, :X, :y, :objective, :σρs, :σs, :corr, :vcov, :PCA, :rePCA, :LMM, :β, :θ, :b, :u, :resp, :wt)</code></pre><p>The variance-covariance matrix of the fixed-effects coefficients is returned by</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.vcov" href="#StatsAPI.vcov"><code>StatsAPI.vcov</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">vcov(model::StatisticalModel)</code></pre><p>Return the variance-covariance matrix for the coefficients of the model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsAPI.jl/blob/v1.7.1/src/statisticalmodel.jl#L151-L155">source</a></section></article><pre><code class="language-julia hljs">vcov(fm2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 Matrix{Float64}:
 43.9874   -1.37052
 -1.37052   2.25673</code></pre><pre><code class="language-julia hljs">vcov(gm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">7×7 Matrix{Float64}:
  0.148388    -0.00561464   -0.00982298   …  -0.0112061    -0.0113458
 -0.00561464   0.000280643   7.19086e-5      -1.47973e-5    1.02416e-5
 -0.00982298   7.19086e-5    0.0365586       -8.04336e-5    5.25819e-5
 -0.0167971   -1.43715e-5   -9.25519e-5       0.000265793  -0.000172092
 -0.0166211   -2.90571e-5   -0.000162372      0.00065896   -0.00052052
 -0.0112061   -1.47973e-5   -8.04336e-5   …   0.0228574    -0.00024778
 -0.0113458    1.02416e-5    5.25819e-5      -0.00024778    0.0228009</code></pre><p>The standard errors are the square roots of the diagonal elements of the estimated variance-covariance matrix of the fixed-effects coefficient estimators.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.stderror" href="#StatsAPI.stderror"><code>StatsAPI.stderror</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">stderror(model::StatisticalModel)</code></pre><p>Return the standard errors for the coefficients of the model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsAPI.jl/blob/v1.7.1/src/statisticalmodel.jl#L144-L148">source</a></section></article><pre><code class="language-julia hljs">stderror(fm2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 6.632297942343554
 1.502240680664057</code></pre><pre><code class="language-julia hljs">stderror(gm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">7-element Vector{Float64}:
 0.38521128748945005
 0.01675241548930026
 0.19120290837085227
 0.18414923963837124
 0.18650807321698457
 0.15118668987587122
 0.15099961612858606</code></pre><p>Finally, the <code>coeftable</code> generic produces a table of coefficient estimates, their standard errors, and their ratio. The <em>p-values</em> quoted here should be regarded as approximations.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.coeftable" href="#StatsAPI.coeftable"><code>StatsAPI.coeftable</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">coeftable(model::StatisticalModel; level::Real=0.95)</code></pre><p>Return a table with coefficients and related statistics of the model. <code>level</code> determines the level for confidence intervals (by default, 95%).</p><p>The returned <code>CoefTable</code> object implements the <a href="https://github.com/JuliaData/Tables.jl/">Tables.jl</a> interface, and can be converted e.g. to a <code>DataFrame</code> via <code>using DataFrames; DataFrame(coeftable(model))</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsAPI.jl/blob/v1.7.1/src/statisticalmodel.jl#L22-L31">source</a></section></article><pre><code class="language-julia hljs">coeftable(fm2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">──────────────────────────────────────────────────
                Coef.  Std. Error      z  Pr(&gt;|z|)
──────────────────────────────────────────────────
(Intercept)  251.405      6.6323   37.91    &lt;1e-99
days          10.4673     1.50224   6.97    &lt;1e-11
──────────────────────────────────────────────────</code></pre><h2 id="Covariance-parameter-estimates"><a class="docs-heading-anchor" href="#Covariance-parameter-estimates">Covariance parameter estimates</a><a id="Covariance-parameter-estimates-1"></a><a class="docs-heading-anchor-permalink" href="#Covariance-parameter-estimates" title="Permalink"></a></h2><p>The covariance parameters estimates, in the form shown in the model summary, are a <code>VarCorr</code> object</p><pre><code class="language-julia hljs">VarCorr(fm2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Variance components:
            Column    Variance Std.Dev.   Corr.
subj     (Intercept)  565.52071 23.78068
         days          32.68242  5.71685 +0.08
Residual              654.94015 25.59180
</code></pre><pre><code class="language-julia hljs">VarCorr(gm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Variance components:
        Column   Variance Std.Dev. 
subj (Intercept)  1.793397 1.339178
item (Intercept)  0.117135 0.342251

</code></pre><p>Individual components are returned by other extractors</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MixedModels.varest" href="#MixedModels.varest"><code>MixedModels.varest</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">varest(m::LinearMixedModel)</code></pre><p>Returns the estimate of σ², the variance of the conditional distribution of Y given B.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/linearmixedmodel.jl#L1340-L1344">source</a></section><section><div><pre><code class="language-julia hljs">varest(m::GeneralizedLinearMixedModel)</code></pre><p>Returns the estimate of ϕ², the variance of the conditional distribution of Y given B.</p><p>For models with a dispersion parameter ϕ, this is simply ϕ². For models without a dispersion parameter, this value is <code>missing</code>. This differs from <code>disperion</code>, which returns <code>1</code> for models without a dispersion parameter.</p><p>For Gaussian models, this parameter is often called σ².</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/generalizedlinearmixedmodel.jl#L816-L826">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MixedModels.sdest" href="#MixedModels.sdest"><code>MixedModels.sdest</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">sdest(m::LinearMixedModel)</code></pre><p>Return the estimate of σ, the standard deviation of the per-observation noise.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/linearmixedmodel.jl#L1036-L1040">source</a></section><section><div><pre><code class="language-julia hljs">sdest(m::GeneralizedLinearMixedModel)</code></pre><p>Return the estimate of the dispersion, i.e. the standard deviation of the per-observation noise.</p><p>For models with a dispersion parameter ϕ, this is simply ϕ. For models without a dispersion parameter, this value is <code>missing</code>. This differs from <code>disperion</code>, which returns <code>1</code> for models without a dispersion parameter.</p><p>For Gaussian models, this parameter is often called σ.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/generalizedlinearmixedmodel.jl#L717-L727">source</a></section></article><pre><code class="language-julia hljs">varest(fm2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">654.9401543542393</code></pre><pre><code class="language-julia hljs">sdest(fm2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">25.59179857599382</code></pre><pre><code class="language-julia hljs">fm2.σ</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">25.59179857599382</code></pre><h2 id="Conditional-modes-of-the-random-effects"><a class="docs-heading-anchor" href="#Conditional-modes-of-the-random-effects">Conditional modes of the random effects</a><a id="Conditional-modes-of-the-random-effects-1"></a><a class="docs-heading-anchor-permalink" href="#Conditional-modes-of-the-random-effects" title="Permalink"></a></h2><p>The <code>ranef</code> extractor</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MixedModels.ranef" href="#MixedModels.ranef"><code>MixedModels.ranef</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ranef(m::LinearMixedModel; uscale=false)</code></pre><p>Return, as a <code>Vector{Matrix{T}}</code>, the conditional modes of the random effects in model <code>m</code>.</p><p>If <code>uscale</code> is <code>true</code> the random effects are on the spherical (i.e. <code>u</code>) scale, otherwise on the original scale.</p><p>For a named variant, see <a href="#MixedModels.raneftables"><code>raneftables</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/linearmixedmodel.jl#L916-L925">source</a></section></article><pre><code class="language-julia hljs">ranef(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Matrix{Float64}}:
 [-16.628221179075137 0.36951602620083934 … 53.57982379923807 -42.494343013190274]</code></pre><pre><code class="language-julia hljs">fm1.b</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Matrix{Float64}}:
 [-16.628221179075137 0.36951602620083934 … 53.57982379923807 -42.494343013190274]</code></pre><p>returns the <em>conditional modes</em> of the random effects given the observed data. That is, these are the values that maximize the conditional density of the random effects given the observed data. For a <code>LinearMixedModel</code> these are also the conditional means.</p><p>These are sometimes called the <em>best linear unbiased predictors</em> or <a href="https://en.wikipedia.org/wiki/Best_linear_unbiased_prediction"><code>BLUPs</code></a> but that name is not particularly meaningful.</p><p>At a superficial level these can be considered as the &quot;estimates&quot; of the random effects, with a bit of hand waving, but pursuing this analogy too far usually results in confusion.</p><p>To obtain tables associating the values of the conditional modes with the levels of the grouping factor, use</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MixedModels.raneftables" href="#MixedModels.raneftables"><code>MixedModels.raneftables</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">raneftables(m::MixedModel; uscale = false)</code></pre><p>Return the conditional means of the random effects as a <code>NamedTuple</code> of Tables.jl-compliant tables.</p><div class="admonition is-info" id="Note-41e0f6281183b665"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-41e0f6281183b665" title="Permalink"></a></header><div class="admonition-body"><p>The API guarantee is only that the NamedTuple contains Tables.jl tables and not on the particular concrete type of each table.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/mixedmodel.jl#L169-L176">source</a></section></article><p>as in</p><pre><code class="language-julia hljs">DataFrame(only(raneftables(fm1)))</code></pre><div><div style = "float: left;"><span>6×2 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">batch</th><th style = "text-align: left;">(Intercept)</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "String" style = "text-align: left;">String</th><th title = "Float64" style = "text-align: left;">Float64</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">A</td><td style = "text-align: right;">-16.6282</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">B</td><td style = "text-align: right;">0.369516</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: left;">C</td><td style = "text-align: right;">26.9747</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">4</td><td style = "text-align: left;">D</td><td style = "text-align: right;">-21.8014</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">5</td><td style = "text-align: left;">E</td><td style = "text-align: right;">53.5798</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">6</td><td style = "text-align: left;">F</td><td style = "text-align: right;">-42.4943</td></tr></tbody></table></div><p>The corresponding conditional variances are returned by</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MixedModels.condVar" href="#MixedModels.condVar"><code>MixedModels.condVar</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">condVar(m::LinearMixedModel)</code></pre><p>Return the conditional variances matrices of the random effects.</p><p>The random effects are returned by <code>ranef</code> as a vector of length <code>k</code>, where <code>k</code> is the number of random effects terms.  The <code>i</code>th element is a matrix of size <code>vᵢ × ℓᵢ</code>  where <code>vᵢ</code> is the size of the vector-valued random effects for each of the <code>ℓᵢ</code> levels of the grouping factor.  Technically those values are the modes of the conditional distribution of the random effects given the observed data.</p><p>This function returns an array of <code>k</code> three dimensional arrays, where the <code>i</code>th array is of size <code>vᵢ × vᵢ × ℓᵢ</code>.  These are the diagonal blocks from the conditional variance-covariance matrix,</p><pre><code class="nohighlight hljs">s² Λ(Λ&#39;Z&#39;ZΛ + I)⁻¹Λ&#39;</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/ef7f09aede1746592a83492cd8b218d0a004c7aa/src/linearmixedmodel.jl#L302-L319">source</a></section></article><pre><code class="language-julia hljs">condVar(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Array{Float64, 3}}:
 [362.3104691431006;;; 362.3104691431006;;; 362.3104691431006;;; 362.3104691431006;;; 362.3104691431006;;; 362.3104691431006]</code></pre><h2 id="Case-wise-diagnostics-and-residual-degrees-of-freedom"><a class="docs-heading-anchor" href="#Case-wise-diagnostics-and-residual-degrees-of-freedom">Case-wise diagnostics and residual degrees of freedom</a><a id="Case-wise-diagnostics-and-residual-degrees-of-freedom-1"></a><a class="docs-heading-anchor-permalink" href="#Case-wise-diagnostics-and-residual-degrees-of-freedom" title="Permalink"></a></h2><p>The <code>leverage</code> values</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StatsAPI.leverage" href="#StatsAPI.leverage"><code>StatsAPI.leverage</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">leverage(model::RegressionModel)</code></pre><p>Return the diagonal of the projection matrix of the model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/StatsAPI.jl/blob/v1.7.1/src/regressionmodel.jl#L51-L55">source</a></section></article><pre><code class="language-julia hljs">leverage(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">30-element Vector{Float64}:
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 ⋮
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158
 0.1565053420672158</code></pre><p>are used in diagnostics for linear regression models to determine cases that exert a strong influence on their own predicted response.</p><p>The documentation refers to a &quot;projection&quot;. For a linear model without random effects the fitted values are obtained by orthogonal projection of the response onto the column span of the model matrix and the sum of the leverage values is the dimension of this column span. That is, the sum of the leverage values is the rank of the model matrix and <code>n - sum(leverage(m))</code> is the degrees of freedom for residuals. The sum of the leverage values is also the trace of the so-called &quot;hat&quot; matrix, <code>H</code>. (The name &quot;hat matrix&quot; reflects the fact that <span>$\hat{\mathbf{y}} = \mathbf{H} \mathbf{y}$</span>.  That is, <code>H</code> puts a hat on <code>y</code>.)</p><p>For a linear mixed model the sum of the leverage values will be between <code>p</code>, the rank of the fixed-effects model matrix, and <code>p + q</code> where <code>q</code> is the total number of random effects. This number does not represent a dimension (or &quot;degrees of freedom&quot;) of a linear subspace of all possible fitted values because the projection is not an orthogonal projection. Nevertheless, it is a reasonable measure of the effective degrees of freedom of the model and <code>n - sum(leverage(m))</code> can be considered the effective residual degrees of freedom.</p><p>For model <code>fm1</code> the dimensions are</p><pre><code class="language-julia hljs">n, p, q, k = size(fm1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(30, 1, 6, 1)</code></pre><p>which implies that the sum of the leverage values should be in the range [1, 7]. The actual value is</p><pre><code class="language-julia hljs">sum(leverage(fm1))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4.695160262016475</code></pre><p>For model <code>fm2</code> the dimensions are</p><pre><code class="language-julia hljs">n, p, q, k = size(fm2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(180, 2, 36, 1)</code></pre><p>providing a range of [2, 38] for the effective degrees of freedom for the model. The observed value is</p><pre><code class="language-julia hljs">sum(leverage(fm2))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">28.61167027736884</code></pre><p>When a model converges to a singular covariance, such as</p><pre><code class="language-julia hljs">fm3 = fit(MixedModel, @formula(yield ~ 1+(1|batch)), MixedModelsDatasets.dataset(:dyestuff2))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 yield ~ 1 + (1 | batch)
   logLik   -2 logLik     AIC       AICc        BIC    
   -81.4365   162.8730   168.8730   169.7961   173.0766

Variance components:
            Column   Variance Std.Dev.
batch    (Intercept)   0.00000 0.00000
Residual              13.34610 3.65323
 Number of obs: 30; levels of grouping factors: 6

  Fixed-effects parameters:
───────────────────────────────────────────────
              Coef.  Std. Error     z  Pr(&gt;|z|)
───────────────────────────────────────────────
(Intercept)  5.6656    0.666986  8.49    &lt;1e-16
───────────────────────────────────────────────</code></pre><p>the effective degrees of freedom is the lower bound.</p><pre><code class="language-julia hljs">sum(leverage(fm3))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.9999999999999998</code></pre><p>Models for which the estimates of the variances of the random effects are large relative to the residual variance have effective degrees of freedom close to the upper bound.</p><pre><code class="language-julia hljs">fm4 = fit(MixedModel, @formula(diameter ~ 1+(1|plate)+(1|sample)),
    MixedModelsDatasets.dataset(:penicillin))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by maximum likelihood
 diameter ~ 1 + (1 | plate) + (1 | sample)
   logLik   -2 logLik     AIC       AICc        BIC    
  -166.0942   332.1883   340.1883   340.4761   352.0676

Variance components:
            Column   Variance Std.Dev. 
plate    (Intercept)  0.714993 0.845572
sample   (Intercept)  3.135139 1.770632
Residual              0.302426 0.549932
 Number of obs: 144; levels of grouping factors: 24, 6

  Fixed-effects parameters:
─────────────────────────────────────────────────
               Coef.  Std. Error      z  Pr(&gt;|z|)
─────────────────────────────────────────────────
(Intercept)  22.9722     0.74459  30.85    &lt;1e-99
─────────────────────────────────────────────────</code></pre><pre><code class="language-julia hljs">sum(leverage(fm4))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">27.465347288682793</code></pre><p>Also, a model fit by the REML criterion generally has larger estimates of the variance components and hence a larger effective degrees of freedom.</p><pre><code class="language-julia hljs">fm4r = fit(MixedModel, @formula(diameter ~ 1+(1|plate)+(1|sample)),
    MixedModelsDatasets.dataset(:penicillin), REML=true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Linear mixed model fit by REML
 diameter ~ 1 + (1 | plate) + (1 | sample)
 REML criterion at convergence: 330.8605889910177

Variance components:
            Column   Variance Std.Dev. 
plate    (Intercept)  0.716908 0.846704
sample   (Intercept)  3.730916 1.931558
Residual              0.302415 0.549923
 Number of obs: 144; levels of grouping factors: 24, 6

  Fixed-effects parameters:
─────────────────────────────────────────────────
               Coef.  Std. Error      z  Pr(&gt;|z|)
─────────────────────────────────────────────────
(Intercept)  22.9722    0.808573  28.41    &lt;1e-99
─────────────────────────────────────────────────</code></pre><pre><code class="language-julia hljs">sum(leverage(fm4r))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">27.472361993617362</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« MixedModels.jl Documentation</a><a class="docs-footer-nextpage" href="../optimization/">Details of the parameter estimation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 26 August 2025 15:12">Tuesday 26 August 2025</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
