# Model constructors

The `LinearMixedModel` type represents a linear mixed-effects model.
Typically it is constructed from a `Formula` and an appropriate `data` type, usually a `DataFrame`.
```@docs
LinearMixedModel
```

## Examples of linear mixed-effects model fits

For illustration, several data sets from the *lme4* package for *R* are made available in `.rda` format in this package.
These include the `Dyestuff` and `Dyestuff2` data sets.
```{julia;term=true}
using DataFrames, MixedModels, RData, StatsBase
const dat = Dict(Symbol(k)=>v for (k,v) in
    load(joinpath(dirname(pathof(MixedModels)), "..", "test", "dat.rda")));
describe(dat[:Dyestuff])
```
The columns in these data sets have been renamed for convenience.
The response is always named `Y`.
Potential grouping factors for random-effects terms are named `G`, `H`, etc.
Numeric covariates are named starting with `U`.
Categorical covariates not suitable as grouping factors are named starting with `A`.


### Models with simple, scalar random effects

The formula language in *Julia* is similar to that in *R* except that the formula must be enclosed in a call to the `@formula` macro.
A basic model with simple, scalar random effects for the levels of `G` (the batch of an intermediate product, in this case) is declared and fit as
```{julia;term=true}
fm1 = fit!(LinearMixedModel(@formula(Y ~ 1 + (1|G)), dat[:Dyestuff]))
```

An alternative expression is
```{julia;term=true}
fm1 = fit(MixedModel, @formula(Y ~ 1 + (1|G)), dat[:Dyestuff])
```
(If you are new to Julia you may find that this first fit takes an unexpectedly long time, due to Just-In-Time (JIT) compilation of the code.
The second and subsequent calls to such functions are much faster.)

```{julia;term=true}
@time fit(MixedModel, @formula(Y ~ 1 + (1|G)), dat[:Dyestuff2]);
```

By default, the model fit is by maximum likelihood.  To use the `REML` criterion instead, add the optional named argument `REML = true` to the call to `fit!`
```{julia;term=true}
fm1R = fit(MixedModel, @formula(Y ~ 1 + (1|G)), dat[:Dyestuff], REML=true)
```

### Simple, scalar random effects

A simple, scalar random effects term in a mixed-effects model formula is of the form `(1|G)`.
All random effects terms end with `|G` where `G` is the *grouping factor* for the random effect.
The name or, more generally, the expression `G` should evaluate to a categorical array that has a distinct set of *levels*.
The random effects are associated with the levels of the grouping factor.

A *scalar* random effect is, as the name implies, one scalar value for each level of the grouping factor.
A *simple, scalar* random effects term is of the form, `(1|G)`.
It corresponds to a shift in the intercept for each level of the grouping factor.

### Models with vector-valued random effects

The *sleepstudy* data are observations of reaction time, `Y`, on several subjects, `G`, after 0 to 9 days of sleep deprivation, `U`.
A model with random intercepts and random slopes for each subject, allowing for within-subject correlation of the slope and intercept, is fit as
```{julia;term=true}
fm2 = fit(MixedModel, @formula(Y ~ 1 + U + (1+U|G)), dat[:sleepstudy])
```

### Models with multiple, scalar random-effects terms

A model for the *Penicillin* data incorporates random effects for the plate, `G`, and for the sample, `H`.
As every sample is used on every plate these two factors are *crossed*.
```{julia;term=true}
fm4 = fit(MixedModel, @formula(Y ~ 1 + (1|G) + (1|H)), dat[:Penicillin])
```

In contrast the sample, `G`, grouping factor is *nested* within the batch, `H`, grouping factor in the *Pastes* data.
That is, each level of `G` occurs in conjunction with only one level of `H`.
```{julia;term=true}
fm5 = fit(MixedModel, @formula(Y ~ 1 + (1|G) + (1|H)), dat[:Pastes])
```

In observational studies it is common to encounter *partially crossed* grouping factors.
For example, the *InstEval* data are course evaluations by students, `G`, of instructors, `H`.
Additional covariates include the academic department, `I`, in which the course was given and `A`, whether or not it was a service course.
```{julia;term=true}
fm6 = fit!(LinearMixedModel(@formula(Y ~ 1 + A * I + (1|G) + (1|H)), dat[:InstEval]))
```

### Simplifying the random effect correlation structure

MixedEffects.jl estimates not only the *variance* of the effects for each random effect level, but also the *correlation* between the random effects for different predictors.
So, for the model of the *sleepstudy* data above, one of the parameters that is estimated is the correlation between each subject's random intercept (i.e., their baseline reaction time) and slope (i.e., their particular change in reaction time over days of sleep deprivation).
In some cases, you may wish to simplify the random effects structure by removing these correlation parameters.
This often arises when there are many random effects you want to estimate (as is common in psychological experiments with many conditions and covariates), since the number of random effects parameters increases as the square of the number of predictors, making these models difficult to estimate from limited data.

A model with uncorrelated random effects for the intercept and slope by subject is fit as
```{julia;term=true}
fm3 = fit!(zerocorr!(LinearMixedModel(@formula(Y ~ 1 + U + (1+U|G)), dat[:sleepstudy])))
```

Note that the use of `zerocorr!` requires the model to be constructed, then altered to eliminate
the correlation of the random effects, then fit with a call to the mutating function, `fit!`.
```@docs
zerocorr!
```

The special syntax `zerocorr` can be applied to individual random effects terms inside the `@formula`:
```{julia;term=true}
fit(MixedModel, @formula(Y ~ 1 + U + zerocorr(1+U|G)), dat[:sleepstudy])
```

Alternatively, correlations between parameters can be removed by including them as separate random effects terms:
```{julia;term=true}
fit(MixedModel, @formula(Y ~ 1 + U + (1|G) + (0+U|G)), dat[:sleepstudy])
```
Note that it's necessary to explicitly block the inclusion of an intercept term by adding `0`.

Finally, for predictors that are categorical, MixedModels.jl will estimate correlations between each level.
Notice the large number of correlation parameters if we treat `U` as a categorical variable by giving it contrasts:
```{julia;term=true}
fit(MixedModel, @formula(Y ~ 1 + U + (1+U|G)), dat[:sleepstudy], contrasts=Dict(:U=>DummyCoding()))
```

Separating the `1` and `U` random effects into separate terms removes the correlations between the intercept and the levels of `U`, but not between the levels themselves:
```{julia;term=true}
fit(MixedModel, @formula(Y ~ 1 + U + (1|G) + (0+U|G)), dat[:sleepstudy], contrasts=Dict(:U=>DummyCoding()))
```

But using `zerocorr` on the individual terms (or `zerocorr!` on the constructed model object as above) does remove the correlations between the levels:
```{julia;term=true}
fit(MixedModel, @formula(Y ~ 1 + U + zerocorr(1+U|G)), dat[:sleepstudy], contrasts=Dict(:U=>DummyCoding()))
fit(MixedModel, @formula(Y ~ 1 + U + (1|G) + zerocorr(0+U|G)), dat[:sleepstudy], contrasts=Dict(:U=>DummyCoding()))
```

## Fitting generalized linear mixed models

To create a GLMM representation
```@docs
GeneralizedLinearMixedModel
```
the distribution family for the response, and possibly the link function, must be specified.

```{julia;term=true}
verbaggform = @formula(r2 ~ 1 + a + g + b + s + m + (1|id) + (1|item));
gm1 = fit(MixedModel, verbaggform, dat[:VerbAgg], Bernoulli())
```

The canonical link, which is `GLM.LogitLink` for the `Bernoulli` distribution, is used if no explicit link is specified.

Note that, in keeping with convention in the [`GLM` package](https://github.com/JuliaStats/GLM.jl), the distribution family for a binary (i.e. 0/1) response is the `Bernoulli` distribution.
The `Binomial` distribution is only used when the response is the fraction of trials returning a positive, in which case the number of trials must be specified as the case weights.

### Optional arguments to fit!

An alternative approach is to create the `GeneralizedLinearMixedModel` object then call `fit!` on it.
In this form optional arguments `fast` and/or `nAGQ` can be passed to the optimization process.

As the name implies, `fast=true`, provides a faster but somewhat less accurate fit.
These fits may suffice for model comparisons.
```{julia;term=true}
gm1a = fit!(GeneralizedLinearMixedModel(verbaggform, dat[:VerbAgg], Bernoulli()), fast=true)
deviance(gm1a) - deviance(gm1)
@time fit!(GeneralizedLinearMixedModel(verbaggform, dat[:VerbAgg], Bernoulli()));
@time fit!(GeneralizedLinearMixedModel(verbaggform, dat[:VerbAgg], Bernoulli()), fast=true);
```

The optional argument `nAGQ=k` causes evaluation of the deviance function to use a `k` point
adaptive Gauss-Hermite quadrature rule.
This method only applies to models with a single, simple, scalar random-effects term, such as
```{julia;term=true}
contraform = @formula(use ~ 1 + a + abs2(a) + l + urb + (1|d))
@time gm2 = fit!(GeneralizedLinearMixedModel(contraform, dat[:Contraception], Bernoulli()), nAGQ=9)
@time deviance(fit!(GeneralizedLinearMixedModel(contraform, dat[:Contraception], Bernoulli()), nAGQ=9, fast=true))
@time deviance(fit!(GeneralizedLinearMixedModel(contraform, dat[:Contraception], Bernoulli())))
@time deviance(fit!(GeneralizedLinearMixedModel(contraform, dat[:Contraception], Bernoulli()), fast=true))
```

# Extractor functions

`LinearMixedModel` and `GeneralizedLinearMixedModel` are subtypes of `StatsBase.RegressionModel` which, in turn, is a subtype of `StatsBase.StatisticalModel`.
Many of the generic extractors defined in the `StatsBase` package have methods for these models.

## Model-fit statistics

The statistics describing the quality of the model fit include
```@docs
loglikelihood(::StatisticalModel)
aic
bic
dof(::StatisticalModel)
nobs(::StatisticalModel)
```
```{julia;term=true}
loglikelihood(fm1)
aic(fm1)
bic(fm1)
dof(fm1)   # 1 fixed effect, 2 variances
nobs(fm1)  # 30 observations
loglikelihood(gm1)
```

In general the [`deviance`](https://en.wikipedia.org/wiki/Deviance_(statistics)) of a statistical model fit is negative twice the log-likelihood adjusting for the saturated model.
```@docs
deviance(::StatisticalModel)
```

Because it is not clear what the saturated model corresponding to a particular `LinearMixedModel` should be, negative twice the log-likelihood is called the `objective`.
```@docs
objective
```
This value is also accessible as the `deviance` but the user should bear in mind that this doesn't have all the properties of a deviance which is corrected for the saturated model.
For example, it is not necessarily non-negative.
```{julia;term=true}
objective(fm1)
deviance(fm1)
```

The value optimized when fitting a `GeneralizedLinearMixedModel` is the Laplace approximation to the deviance or an adaptive Gauss-Hermite evaluation.
```@docs
MixedModels.deviance!
```
```{julia;term=true}
MixedModels.deviance!(gm1)
```

## Fixed-effects parameter estimates

The `coef` and `fixef` extractors both return the maximum likelihood estimates of the fixed-effects coefficients.
```@docs
coef
fixef
```
```{julia;term=true}
show(coef(fm1))
show(fixef(fm1))
show(fixef(gm1))
```

An alternative extractor for the fixed-effects coefficient is the `β` property.
Properties whose names are Greek letters usually have an alternative spelling, which is the name of the Greek letter.
```{julia;term=true}
show(fm1.β)
show(fm1.beta)
show(gm1.β)
```
The variance-covariance matrix of the fixed-effects coefficients is returned by
```@docs
vcov
```
```{julia;term=true}
vcov(fm2)
vcov(gm1)
```

The standard errors are the square roots of the diagonal elements of the estimated variance-covariance matrix of the fixed-effects coefficient estimators.
```@docs
stderror
```
```{julia;term=true}
show(StatsBase.stderror(fm2))
show(StatsBase.stderror(gm1))
```

Finally, the `coeftable` generic produces a table of coefficient estimates, their standard errors, and their ratio.
The *p-values* quoted here should be regarded as approximations.
```@docs
coeftable
```
```{julia;term=true}
coeftable(fm2)
```

## Covariance parameter estimates

The covariance parameters estimates, in the form shown in the model summary, are a `VarCorr` object
```@docs
VarCorr
```
```{julia;term=true}
VarCorr(fm2)
VarCorr(gm1)
```

Individual components are returned by other extractors
```@docs
varest
sdest
```
```{julia;term=true}
varest(fm2)
sdest(fm2)
fm2.σ
```

## Conditional modes of the random effects

The `ranef` extractor
```@docs
ranef
```
```{julia;term=true}
ranef(fm1)
fm1.b
```
returns the *conditional modes* of the random effects given the observed data.
That is, these are the values that maximize the conditional density of the random effects given the observed data.
For a `LinearMixedModel` these are also the conditional mean values.

These are sometimes called the *best linear unbiased predictors* or [`BLUPs`](https://en.wikipedia.org/wiki/Best_linear_unbiased_prediction) but that name is not particularly meaningful.

At a superficial level these can be considered as the "estimates" of the random effects, with a bit of hand waving, but pursuing this analogy too far usually results in confusion.

The corresponding conditional variances are returned by
```@docs
condVar
```
```{julia;term=true}
condVar(fm1)
```
